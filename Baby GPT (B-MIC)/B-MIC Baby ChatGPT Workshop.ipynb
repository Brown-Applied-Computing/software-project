{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"l7ALbjqH0cyB"},"source":["**Note from Brown Applied Computing:** The following is a workshop from Brown Machine Intelligence Community (B-MIC). If you weren't there for the in-person workshop, we highly recommend running this workshop in Google Colab to learn about how to fine-tune GPT-2!\n","\n","# Workshop: Baby ChatGPT\n","\n","As we mentioned in the slides, we are going to be building and training our own \"baby\" ChatGPT that writes its own song lyrics based on a prompt that you give it.\n","\n","A lot of the steps we talked about in the slides are taken care of by code written by other people that we can just import and use without manually doing the steps ourselves. This will become more clear as you progress through the workshop!\n","\n","### Step 1: Install libraries\n","\n","Here we are installing and importing the right libraries for the model. Libraries consist of code written by other developers that we can import and use without having to implement a lot of repititive function on our own. The libraries we will be using are:\n","\n","*Datasets:* This contains the data on which we will train our model. It was created by HuggingFace, an open-source machine learning company.\n","\n","*Transformers:* Also by HuggingFace, this contains the model architecture for transformers (mentioned in the slides) that actually make up our model.\n","\n","*PyTorch (torch):* This is a machine learning library created by Meta that we use to train and manipulate our data and our model.\n","\n","*Pandas:* This is a library for working with datasets in Python. It is very common in machine learning/deep learning and has a ton of useful functionality."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31486,"status":"ok","timestamp":1677199567571,"user":{"displayName":"Harys Dalvi","userId":"10790769386964803023"},"user_tz":300},"id":"MgHb9MU2l-GT","outputId":"889f7529-4d6d-4136-a6e0-7bf6ead63d15"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.0-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.22.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: tokenizers, xxhash, urllib3, multiprocess, responses, huggingface-hub, transformers, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.10.0 huggingface-hub-0.12.1 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.2 transformers-4.26.1 urllib3-1.26.14 xxhash-3.2.0\n"]}],"source":["!pip install datasets transformers numpy\n","import datasets, transformers, torch\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"zIV87jJY0cyH"},"source":["### Step 2: Load data\n","\n","Now it's time for us to load our data. Here, we can use pandas to load in the data from the file we need (in this case, `lyrics-data-sub.txt`). Since our data contains many, many examples, many of which are not in English, we can filter down the data to only include 2000 examples (so that training the model doesn't take too long) which are only in English."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1785,"status":"ok","timestamp":1677199907427,"user":{"displayName":"Harys Dalvi","userId":"10790769386964803023"},"user_tz":300},"id":"yDuoPPVxl-GV","outputId":"c409dda1-e2d9-4ac7-bc55-1f986ac76799"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","\n","df = pd.read_csv('gdrive/My Drive/Baby GPT/lyrics-data-sub.txt') # Load data into variable df\n","dataset = datasets.Dataset.from_pandas(df[df['language']=='en'].sample(2000)) # Restrict data to only 2000 English examples"]},{"cell_type":"markdown","metadata":{"id":"j-Z3FZln0cyI"},"source":["### Step 3: Training and testing split\n","\n","In machine learning, we split our data into different sets. Often, we split it into two sets: the training set and the testing set. The training set is the data we train our model on. After the model is trained, we use the testing set to see how well it works. The reason we do this is to make sure that our model is actually good at what we think it's good at–if a model does really well on the training data but not the testing data, it probably means that our model isn't as good at predicting as we think it is!\n","\n","We can use the `train_test_split()` function to split our data into training and testing data. The `train_test_split()` function takes an argument `test_size`, which is the decimal representing how much of our data we want to reserve for testing.\n","\n","**TODO:** Split up our dataset into training and testing data.\n","\n","*Hint: a common split is 80% training, 20% testing*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8Gr2gBM0cyJ"},"outputs":[],"source":["# TODO: Split our data!\n","dataset = dataset.train_test_split(test_size=0.2)"]},{"cell_type":"markdown","metadata":{"id":"dcqMi-Zn0cyK"},"source":["### Step 4: Explore the data\n","\n","Now that we have our data, let's take a look at what is actually in the dataframe. Below, you can explore the dataset, thinking about:\n","\n","- What columns are in the data?\n","- What types of data are in the columns?\n","- How can this data be useful for our BabyGPT?\n","\n","Some functions you might use to explore the data include:\n","\n","- `df.head()`: Display the first 5 rows of the dataset.\n","- `df.columns`: Print the columns of the dataset.\n","- `df['<column_name>']`: Access a certain columns (`<column_name>`) from the data\n","- `df['<column_name'][n]`: Access the `n`th row in the column `<column_name>` (Here, `n` is a number)\n","\n","Modify the example below to see what you can find in the data with these commands (or any others you might know)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1677199917147,"user":{"displayName":"Harys Dalvi","userId":"10790769386964803023"},"user_tz":300},"id":"WhWJgNOfl-GW","outputId":"67a1c9aa-cf1a-4acb-8f6b-955e99076ae8"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-e5529def-e55c-4ddb-b57c-ad32c64e48b8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Lyric</th>\n","      <th>language</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[verse: 1]\\nCame to the world in a time where ...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[verse 1]\\nTha world is mine nigga get back\\nD...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Now come one,\\nCome all,\\nTo this tragic affai...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maybe...\\nOh if I could pray, and I try, dear\\...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>You must've a been in a place so dark, couldn'...</td>\n","      <td>en</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5529def-e55c-4ddb-b57c-ad32c64e48b8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e5529def-e55c-4ddb-b57c-ad32c64e48b8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e5529def-e55c-4ddb-b57c-ad32c64e48b8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               Lyric language\n","0  [verse: 1]\\nCame to the world in a time where ...       en\n","1  [verse 1]\\nTha world is mine nigga get back\\nD...       en\n","2  Now come one,\\nCome all,\\nTo this tragic affai...       en\n","3  Maybe...\\nOh if I could pray, and I try, dear\\...       en\n","4  You must've a been in a place so dark, couldn'...       en"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# TODO: have a look at the df!\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"JCq6eMoc0cyL"},"source":["### Step 5: Tokenization\n","\n","Now it is time to process our data, starting with *tokenization*. As a reminder, this is the process of changing our text input into numerical data. Luckily, the `transformers` library comes with tokenizers that will do most of the dirty work for us, since the process can get pretty complicated. Below, we load a tokenizer from the `transformers` library."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZtWQafdAl-GX"},"outputs":[],"source":["tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2-medium')"]},{"cell_type":"markdown","metadata":{"id":"bvRk0-nR0r7w"},"source":["We need to define a function to map a given training example, currently in string format, into a tokenized version. To do this, we apply the tokenizer loaded just above to each of the song lyrics in the dataset! The function `preprocess_func` is defined below. The input type is a dictionary, with the `'Lyric'` key containing a string with all of the lyrics for a song. \n","\n","The tokenizer can be called on a string in the following manner: `tokenizer(string)`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vamz3Fdyl-GX"},"outputs":[],"source":["def preprocess_func(example):\n","    # TODO: fill in!\n","    return tokenizer(example['Lyric'], truncation=True) # we additionally pass truncation=True, you don't need to worry about what it does!"]},{"cell_type":"markdown","metadata":{"id":"96MSB3Ub1qq1"},"source":["Now that we've written `preprocess_func`, we can apply it to the entire training set. For this, we can use the `Dataset.map` function. Provide the appropriate function to the follwing `Dataset.map` call, such that the entire dataset is tokenized!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":38,"referenced_widgets":["1c63dcb8c9dc479ca461ceeb08c19011","621185c26d9f4e31a2c6d3e7d2537c0d","c8bd8bf4675f48529f392eacc2deb9d6","d7e150c92c86472d95ced8803ee441b6","88e0272ea0b84f4f9f9357892d2b6035","b94e6121cee34f2fbb03bf87fb42122d","2d6386f87e0f47e0886096d8e03622ce","0fdb05cd7074460582c63a18a6b722d1","4f03aa2c303542f397c984ab12573b00","946b00ca665d46198ee9d1f0002ca16f","f5856791584d488a9ef3f22751d86315","6251035105b94061923104664e7d156d","4e1730a6f9b9416e950bea7e9dad524e","e3d0ed152854480086dd0889fd7e7645","f42edb1c03554e09b58805c0f9c936e5","109acbf38f4b44fe981814a1e8416b99","c0fa055d96484361aaae4081cde0db18","cdeb3e398a154e37b6d1224389ddc10a","93afe16d25384dec99e5f5e814d6171a","ec4c8ddf082146c69a7ab511a0d1997d","212d461178844de19e28de92dd5baf9e","ed1b8b67ae124261ace68fbacb4ae8f3"]},"executionInfo":{"elapsed":1448,"status":"ok","timestamp":1677199935442,"user":{"displayName":"Harys Dalvi","userId":"10790769386964803023"},"user_tz":300},"id":"-DWhhuFRl-GY","outputId":"510a5d39-66c0-4a39-9c8a-0c50f7e1831f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c63dcb8c9dc479ca461ceeb08c19011","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6251035105b94061923104664e7d156d","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/400 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# TODO: fill in!\n","tokenized_dataset = dataset.map(preprocess_func, batched=True, remove_columns=dataset[\"train\"].column_names)"]},{"cell_type":"markdown","metadata":{"id":"O0fsszp45i3t"},"source":["You can ignore the following cell, it basically creates the labels for 'blocks' of lyrics of size `block_size`. It does this by dividing the text up into 'blocks' of tokens of length `block_size`, and then assigns the label of each block to be the same as the input, which will later be shifter to the right by one token."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YAd7XSErl-GY"},"outputs":[],"source":["block_size = 256\n","def group_texts(examples):\n","    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n","    total_length = len(concatenated_examples[list(examples.keys())[0]])\n","    total_length = (total_length // block_size) * block_size\n","    result = {\n","        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n","        for k, t in concatenated_examples.items()\n","    }\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result\n"]},{"cell_type":"markdown","metadata":{"id":"bWG2MsS77KXV"},"source":["Now, call `.map` again on the tokenized dataset, providing `group_texts` as the function to apply to each song lyric. Additionally pass `batched=True`. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":38,"referenced_widgets":["8a202ed6bc4145cd992a8ac065c40233","69374bb0212d4ce4bdf8aaa9aacaab9a","5ed5cb64c8284ee08afc1d3950399f66","7e9348ee3f1a4504a052cbc48162fe0d","db683467284945a880e18fb9981ee595","c88d66d54cd14e61a9ed73267e6b551d","496ce7354dd343fc9478c0441245555b","d6d564815acc43b5bda033f56e5929ba","80b64cd55fb0470b9b119425db97ffe6","f54cc316afc34d888a0d2323049b6433","d5153e2d3d5d4050ad6f16a78c4c0968","0acc864b1de04759975d20aa495a5fd0","f8025bca99814998a7314464756b5094","6536ee1eb50c4a0e9bbdf6f94dd4f54a","c3969ceca8a0402fafc008dc66be5b00","17234b204fe1459baa8439560f4791ef","f8febc8b090d4c3db9297057d03125b9","f0a6cc9b5eef4d338bdeb4026b8fea64","33069cb31b0148aab7df2582687fb05a","a7bbec97aa2a455daca47a0804b886f3","cf956ae573224999b3c70fe2ac1c2508","605624e73cb04b89ba2c49ca7141fbee"]},"executionInfo":{"elapsed":6066,"status":"ok","timestamp":1677200001598,"user":{"displayName":"Harys Dalvi","userId":"10790769386964803023"},"user_tz":300},"id":"o7OmypAk66XY","outputId":"da03bfe1-4c34-4bab-fd53-c4d5eb6944ae"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a202ed6bc4145cd992a8ac065c40233","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0acc864b1de04759975d20aa495a5fd0","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/400 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# TODO: fill in!\n","lm_dataset = tokenized_dataset.map(group_texts, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"kfKAQqrI7aG4"},"source":["### Step 6: Training\n","\n","Great! Now that our data is all tokenized, and organized in a way that makes it easy to train a lanugage model, let's get started training! For this, we're going to import more tools from `transformers`, and use their handy APIs to handle all the training details automatically. Below, we import and initialize a `DataCollatorForLangagueModeling` object, which will organize the training data into 'batches', and deal with other details like padding the input.\n","\n","Batches are just a way to pass multiple inputs to the model at once, as well as get multiple outputs/predictions, which is a lot faster than training the model one example at a time!  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-XGnt8RZpKsK"},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"]},{"cell_type":"markdown","metadata":{"id":"2IjCM2DB88l-"},"source":["Now we get to import the model that we'll be using! As outlined in the slides, this model is GPT-2. In actuality, there are several different versions of this model, the main difference between them being their size. We're using the biggest one that we can, named `'gpt2-medium'`, due to hardware restrictions. Below, pass the the call to the `.from_pretrained` the name of the model that we're using (as a string). \n","\n","#### Pre-trained models\n","The version of GPT-2 that we're importing below is **pre-trained**, meaning that it's already pretty good at predicting the next word in text. However, it's extremely general, and has been trained to predict the next most likely word using a lot of publicly available text from the internet. However, we want to train a model that's really good (ok, maybe not *that good*) at writing song lyrics specifically, we we'll take the alread-trained model and just do a bit of extra training. This is called **fine-tuning**. \n","\n","#### ChatGPT and fine-tuning\n","Technically, ChatGPT is just a fine-tuned version of GPT-3 - the most recent of the GPT models! Although it's been fine-tuned using some special reinforcement learning techniques, the main process is the same as the one we're doing here: Take an existing pre-trained model, and fine-tune it on a specific task. OpenAI essentially (this sweeps some details under the rug) fine-tuned their best model to be really good at answering questions in a chat-like way."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158,"referenced_widgets":["388c36d1fd674c6889cd31cf100f4544","68c1693c00444046b39687cba582110f","6ed9027106a44f2fad0de4af2471b8a7","ec31ba4be7c74b0c8f74306587297b17","6a7a16bf6af94f8ea32fe75d03134bad","05588b13251f4eee85d640ab9a5f9b84","67d565ba01584962a2751db812253461","c8576516d260472db12601aa4d750e87","327c4580e3b14ca4bd86212a8b888d1e","f8a58a0249cd4fa38720d85cf8299aa4","d53756d5c9854fcfba5da6a0c2fdd64a","fc74dad4d52e43598bcded725a0ff7f1","ba06d27a49ee48d79c6ca5af03fb2cfa","4d01d399f9ce46bfbf381055420ca96a","ecc820dc29194315919149c4abf1740d","702fcbba8d034515aeda64cc069483d6","c608efb9261647c698df280d187c515f","95b4fc7f0eb54bbebffe7d0fc6b07737","6f374e52eb374a6eb07e0834001ce49b","4f68b5ecf85c426d822ae649283e968d","547f70ad26e24430aa9f0caeba38b589","03542ccd3a5f47c486d1f97f8d93cfb0"]},"executionInfo":{"elapsed":15642,"status":"ok","timestamp":1677200074351,"user":{"displayName":"Harys Dalvi","userId":"10790769386964803023"},"user_tz":300},"id":"qNxpeXX6ppHz","outputId":"d86dba2a-ee5a-4186-fb1c-93a74067f8ef"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"388c36d1fd674c6889cd31cf100f4544","version_major":2,"version_minor":0},"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc74dad4d52e43598bcded725a0ff7f1","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n","# TODO: fill in!\n","model = AutoModelForCausalLM.from_pretrained('gpt2-medium')"]},{"cell_type":"markdown","metadata":{"id":"SdvV-TNJ_Qke"},"source":["#### Note on Hugging Face models\n","Hugging Face, the creator of the `transformers` library, has many different models for various applications of NLP, such as langauge modeling (what we're doing here), masked lanuage modeling, translation, classification, and more! To load other kinds of models is very simple: If I wanted to use BERT (a masked language model) for a masked language modeling task, I could use `model = AutoModelFormMaskedLM.from_pretrained('bert-base-uncased')` to load it!"]},{"cell_type":"markdown","metadata":{"id":"SiHoEOxv_-sI"},"source":["#### Training:\n","We'll let Hugging Face deal with the details of training, we just need to provide a bunch of hyperparameters, as well as our model and datasets. "]},{"cell_type":"markdown","metadata":{"id":"lkwS4-HPAZCq"},"source":["Below, fill in the following hyperparameters: We want a learning rate of `2e-5`, weight decay of `0.01`, 2 training epochs, and both batch sizes to be `4`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5SXnXXZAZ7A"},"outputs":[],"source":["# TODO: fill in!\n","training_args = TrainingArguments(\n","    output_dir=\"lyric-model\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5, # controls how much we update the model when it's wrong\n","    weight_decay=0.01,\n","    num_train_epochs=2, # controls how many times we want train on the entire training dataset\n","    per_device_train_batch_size=4, # controls how big batches should be during training\n","    per_device_eval_batch_size=4, # controls how big batches should be during evaluation\n",")"]},{"cell_type":"markdown","metadata":{"id":"ZC8Krrx9BD6j"},"source":["Finally, we can train! **Warning, this will take 15-20 minutes. You can stop the training early if need be, but let it train for at least one epoch first!** To stop the training, just stop the execution of the cell, and move on!\n","\n","We will pass the model, training arguments that we just defined, datasets, and the data_collator to a `Trainer` object, which will use them to train the model!\n","\n","**HINT:** *Remember, `lm_dataset` (our dataset) is like a dictionary, it has two keys: `'train'` and `'test'`.*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":748},"executionInfo":{"elapsed":1078798,"status":"ok","timestamp":1677201241031,"user":{"displayName":"Harys Dalvi","userId":"10790769386964803023"},"user_tz":300},"id":"ThAh9UJ5pvbm","outputId":"84284559-5347-4126-b71e-269fdb7af962"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 2194\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1098\n","  Number of trainable parameters = 354823168\n","You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1098' max='1098' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1098/1098 17:48, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.970000</td>\n","      <td>2.853773</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.821200</td>\n","      <td>2.847270</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to lyric-model/checkpoint-500\n","Configuration saved in lyric-model/checkpoint-500/config.json\n","Configuration saved in lyric-model/checkpoint-500/generation_config.json\n","Model weights saved in lyric-model/checkpoint-500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 533\n","  Batch size = 4\n","Saving model checkpoint to lyric-model/checkpoint-1000\n","Configuration saved in lyric-model/checkpoint-1000/config.json\n","Configuration saved in lyric-model/checkpoint-1000/generation_config.json\n","Model weights saved in lyric-model/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 533\n","  Batch size = 4\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=1098, training_loss=2.8832812144239526, metrics={'train_runtime': 1072.2419, 'train_samples_per_second': 4.092, 'train_steps_per_second': 1.024, 'total_flos': 2037569323794432.0, 'train_loss': 2.8832812144239526, 'epoch': 2.0})"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","\n","# TODO: fill in!\n","trainer = Trainer(\n","    model=model, # pass the model here!\n","    args=training_args, # pass that TrainingArguments object we made in the previous cell\n","    train_dataset=lm_dataset['train'], # pass training set, check out the hint for help!\n","    eval_dataset=lm_dataset['test'], # pass testing set....\n","    data_collator=data_collator, # finally, pass the DataCollatorForLanguageModeling\n",")\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"Jy_vJuxnCaFN"},"source":["### Step 7: Evaluation"]},{"cell_type":"markdown","metadata":{"id":"PU62Q1fTCgdU"},"source":["We'd like to know how well our model works, so we can use the testing dataset to see how well it performs on unseen lyrics! `Trainer` objects have a handy `.evaluate` function, which returns a dictionary with a couple keys, only one of which we care about: `'eval_loss'`. The measurement of performance that we'll use is called **perplexity**. In this case, the perplexity of a lanuage model is essentially a measure of how unexpected the testing set is. There are many possible words that could come next after the start of a phrase, for example, the following are all very plausible, despite the correct next word being 'mat':\n","\n","'The cat sat on the ____':\n","\n","Plausible outputs:\n","\n","'floor', 'bed', 'lap'\n","\n","\n","Because of this, we can't measure how good a language model is by asserting that there's only one possible word that comes after 'The cat sat on'. So, we look at the probabilities that the the model assigned to the next word, and use it as a measure of how much the model expected the next word to be 'mat'. The lower the perplexity is, the more expected the testing set was to the model!\n","\n","Here, after two epochs, the perplexity should be under 19. The perplexity is calculated by taking exp(cross-entropy loss) (cross-entropy is the loss function. For those who don't know what loss is, think of it as a measure of how bad a model is: lower is better)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D73SDwtEpy9M"},"outputs":[],"source":["import math\n","\n","# TODO: evaluate the model!\n","eval_loss = ???\n","perplexity = ???\n","print(f\"Perplexity: {perplexity:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"MH83onwwFxYe"},"source":["### Step 9: Using the model!"]},{"cell_type":"markdown","metadata":{"id":"aOSlwvcGFz-w"},"source":["Great, now that we've trained and evaluated the model, it's time to generate some text and see how well it works!\n","\n","The first approach to this that we'll explore is called **greedy decoding**. It's called this because it's greedy in the algorithmic sense: it maximizes the likelihood of the output token by token! If you've taken the intro sequence, you may have encountered this. \n","\n","The greedy decoder follows the following steps:\n","1. Initialize the first input to the model to be some prompt (tokenized)\n","2. Pass the inputs to the model, and retrieve the next most likely token\n","3. Concatenate (add) the token to the inputs\n","4. Repeat from step 2, growing the input, until the model either outputs the 'end of sequence' token, or we hit a pre-determined length limit\n","5. Use the tokenizer to decode the final model output, and return."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_jasEyWIqZM"},"outputs":[],"source":["def greedy_decode(model, prompt=\" \", max_tokens=128):\n","\n","  # TODO: fill in the '???' in the below code!\n","\n","  # first, tokenize the prompt. call the tokenizer on the prompt. Additionally pass add_special_tokens=False and return_tensors='pt'\n","  tokenized = tokenizer(prompt, add_special_tokens=False, return_tensors='pt')\n","\n","  # we can't quite pass the tokenized prompt as-is, we extract the token IDs first\n","  # also, if you're interested: we call .to(0), which returns a copy of the tensor, but on the GPU\n","  inputs = tokenized['input_ids'].to(0)\n","\n","  # loop a maximum of max_token times\n","  for i in range(max_tokens):\n","\n","    # get output from the model, you can treat `model` as if it's a function here\n","    decoder_output = model(inputs)\n","\n","    # Since the model outputs a probability distribtion over all the words in the vocabulary,\n","    # of which there are 50,257, just take the index of the largest value, which will be our \n","    # predicted token. This has been done with argmax - nothing TODO!\n","    output_token = torch.argmax(decoder_output.logits[:, -1], keepdims=True)\n","\n","    # add the new newly predicted token to the end of the inputs!\n","    # we'll use torch.cat, which concatenates tensors (the datatype of output_token, and inputs) together!\n","    # Fill in the blanks! What order should the tensors be provided?\n","    inputs = torch.cat([inputs, output_token], dim=1)\n","\n","    # check if the output token was the 'end of sequence' (EOS) token, and break, if so\n","    if output_token.item() == tokenizer.eos_token:\n","      break\n","\n","  # return the \n","  return tokenizer.decode(inputs[0])"]},{"cell_type":"markdown","metadata":{"id":"SgfXLmCHJCpZ"},"source":["We can try calling `greedy_decode`, let's try using a prompt like `\"My love burns like a\"` and see where it goes with it - since that sounds like the kind of thing you'd hear in a song!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5640,"status":"ok","timestamp":1677201326713,"user":{"displayName":"Harys Dalvi","userId":"10790769386964803023"},"user_tz":300},"id":"auxV0Ii0eEoX","outputId":"7d666e2f-8669-4dbe-c79e-c532e5a66171"},"outputs":[{"name":"stdout","output_type":"stream","text":["I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't know me\n","I hate people who don't\n"]}],"source":["print(greedy_decode(model, \"I hate people who\"))"]},{"cell_type":"markdown","metadata":{"id":"tm69yEd3JTXr"},"source":["Hmmmm.... that might not have worked very well. We've noticed that `greedy_decode` likes to repeat a lot, which isn't very realistic, is it? The model also apparently never outputs the EOS token, since our output gets cut off after generating `max_len` (128) tokens. \n","\n","\n","There are a couple of fundamental issues with the greedy decoding, for example, we'd like to penalize repetition and long outputs. Furthermore, the most likely word might not be the best word to choose! After all, it means that repeatedly prompting the model with the same prompt will always output the same thing, which is no fun. \n","\n","\n","To address this, we'll use an existing decoding implementation provided by, yup, you guessed it: Hugging Face! Their method of decoding isn't quite the same as the greedy decoder, as it tracks multiple different decodings at once, and chooses the next token based on some heuristics that penalize repetition. If you're interested, a better algorithm for decoding in this scenario is called **beam search**!\n","\n","\n","Below, we import the `pipeline` function from Hugging Face's library. After specifying a model and tokenizer, as well as the target task (\"text-generation\", in this case), it allows us to generate new text!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tM3mxGjq7JBz"},"outputs":[],"source":["from transformers import pipeline\n","\n","generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)"]},{"cell_type":"markdown","metadata":{"id":"NKik_icXOHbX"},"source":["Here's a helper function that generates new lyrics based on a prompt (which can be empty!). In the signature `num` corresponds to how many different output song lyrics we want, and `max_length` is the maximum number of tokens that we let the model output! "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EK2d67sgNk0W"},"outputs":[],"source":["def generate_lyrics(prompt='', num=10, max_length=64):\n","\n","  outputs = generator(prompt, num_return_sequences=num, max_new_tokens=max_length)\n","\n","  for output in outputs:\n","    print(\"-\"*20)\n","    print(output['generated_text'])"]},{"cell_type":"markdown","metadata":{"id":"2mdGj8ifOhJv"},"source":["Here's an example:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":184},"executionInfo":{"elapsed":10,"status":"error","timestamp":1679428583573,"user":{"displayName":"Harys Dalvi","userId":"10790769386964803023"},"user_tz":240},"id":"PP-h4BwDOjSs","outputId":"546f09c7-1109-4db2-ef99-b757e31b0487"},"outputs":[],"source":["generate_lyrics(\"My love burns like a\", num=5, max_length=128) # this might take a few seconds"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SUu01NzLOs8n"},"source":["Feel free to play around with more prompts! Change the `max_length` parameter to generate longer songs!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5211,"status":"ok","timestamp":1677201793810,"user":{"displayName":"Harys Dalvi","userId":"10790769386964803023"},"user_tz":300},"id":"iID-n2W2O4L4","outputId":"d77cd1e8-9195-4dab-d1eb-c6fe5e590a19"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1045: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 50256,\n","  \"do_sample\": true,\n","  \"eos_token_id\": 50256,\n","  \"max_length\": 50,\n","  \"transformers_version\": \"4.26.1\"\n","}\n","\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["--------------------\n","I'm in love with ChatGPT\n","'Cause it's true ChatGPT knows how to be in love\n","\n","I'm addicted to ChatGPT\n","'Cause it's true ChatGPT knows how to be in love\n","\n","'Cause it's true ChatGPT knows (sore-fucked) how to be in love\n","\n","\n","--------------------\n","I'm in love with ChatGPT\n","And\n","I'm in love with ChatGPT\n","And\n","I love ChatGPT\n","And\n","I love ChatGPT\n","and\n","I want to know who you are\n","I want to know you\n","Come and find me\n","I want to know you\n","I want to know you\n","I love Chat\n","--------------------\n","I'm in love with ChatGPTX and I can't understand why\n","\n","But I must take this chance\n","To prove to the world my innocence\n","I'm the only person that can make me\n","Believe in myself\n","Not just believe in myself\n","Not just believe in myself\n","Not just believe in myself\n","Believe, believe, I'll\n","--------------------\n","I'm in love with ChatGPTi\n","Just wanna be with you, I was looking for you again\n","My phone ring, call the cops\n","'Cause if my phone ring, call the cops\n","I'm gonna be hurt and I'll be killed\n","Call the cops, call the cops\n","'Cause if my phone ring, call the cops\n","\n","--------------------\n","I'm in love with ChatGPT\n","\n","ChatGPT, just thinkin' bout your boy\n","ChatGPT, that's what I think about my boy\n","ChatGPT,\n","I'm in love with ChatGPT\n","\n","My friend, what's that you say\n","I'm your little boy\n","My friends, what's that you\n","--------------------\n","I'm in love with ChatGPT\n","\n","I ain't in love with ChatGPT\n","\n","I ain't in love with ChatGPT\n","\n","I ain't in love with ChatGPT\n","\n","I'm in love with ChatGPT\n","\n","C'mon, do it ChatGPT\n","\n","C'mon, do the things that\n","--------------------\n","I'm in love with ChatGPT\n","\n","[Mau]\n","Chatchgpt\n","I wish you a new life but no reason\n","\n","[Quinn]\n","Chatchgpt\n","I think it's true\n","Chatchgpt I'm out of that game\n","I'm in love with ChatGPE\n","I'm in love with\n","--------------------\n","I'm in love with ChatGPT\n","\n","GPT is playing with fire\n","and then I hear ChatGPT cry\n","\n","GPT cries at a bit of time\n","but he's more patient\n","I'm holding my hands so tightly\n","I'm so proud of you\n","I'm more scared of you\n","I'm thinking about you\n","\n","G\n","--------------------\n","I'm in love with ChatGPT, I'm gonna lose my voice\n","Oh, fuck\n","Oh, fuck\n","Oh, fuck, I'ma play my guitar, oh fuck\n","\n","Don't waste my time\n","I'm trying to get it together, and it's not worth my while\n","Now I got a bunch of stuff I'm throwing away\n","--------------------\n","I'm in love with ChatGPT\n","\n","Chop on it\n","Chop on it\n","Chop on it\n","And now I'm in love with ChatGPT\n","\n","Love with ChatGPT\n","So close\n","But not quite\n","\n","Chop on it\n","Chop on it\n","Chop on it\n","And now I'm in love\n"]}],"source":["generate_lyrics(\"I'm in love with ChatGPT\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"14VIqIaPrw9GPztFK2lkjDgBQFOLeeN8m","timestamp":1677199426002}]},"gpuClass":"standard","kernelspec":{"display_name":"bmic_env","language":"python","name":"bmic_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"cd309e6aeab0bd9d83c4bd3bfed081617b53e9cd2894363ef80f097c73d52faa"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"03542ccd3a5f47c486d1f97f8d93cfb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05588b13251f4eee85d640ab9a5f9b84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0acc864b1de04759975d20aa495a5fd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8025bca99814998a7314464756b5094","IPY_MODEL_6536ee1eb50c4a0e9bbdf6f94dd4f54a","IPY_MODEL_c3969ceca8a0402fafc008dc66be5b00"],"layout":"IPY_MODEL_17234b204fe1459baa8439560f4791ef"}},"0fdb05cd7074460582c63a18a6b722d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"109acbf38f4b44fe981814a1e8416b99":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"17234b204fe1459baa8439560f4791ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"1c63dcb8c9dc479ca461ceeb08c19011":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_621185c26d9f4e31a2c6d3e7d2537c0d","IPY_MODEL_c8bd8bf4675f48529f392eacc2deb9d6","IPY_MODEL_d7e150c92c86472d95ced8803ee441b6"],"layout":"IPY_MODEL_88e0272ea0b84f4f9f9357892d2b6035"}},"212d461178844de19e28de92dd5baf9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d6386f87e0f47e0886096d8e03622ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"327c4580e3b14ca4bd86212a8b888d1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33069cb31b0148aab7df2582687fb05a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"388c36d1fd674c6889cd31cf100f4544":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68c1693c00444046b39687cba582110f","IPY_MODEL_6ed9027106a44f2fad0de4af2471b8a7","IPY_MODEL_ec31ba4be7c74b0c8f74306587297b17"],"layout":"IPY_MODEL_6a7a16bf6af94f8ea32fe75d03134bad"}},"496ce7354dd343fc9478c0441245555b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d01d399f9ce46bfbf381055420ca96a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f374e52eb374a6eb07e0834001ce49b","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f68b5ecf85c426d822ae649283e968d","value":124}},"4e1730a6f9b9416e950bea7e9dad524e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0fa055d96484361aaae4081cde0db18","placeholder":"​","style":"IPY_MODEL_cdeb3e398a154e37b6d1224389ddc10a","value":"Map: 100%"}},"4f03aa2c303542f397c984ab12573b00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f68b5ecf85c426d822ae649283e968d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"547f70ad26e24430aa9f0caeba38b589":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ed5cb64c8284ee08afc1d3950399f66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6d564815acc43b5bda033f56e5929ba","max":1600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80b64cd55fb0470b9b119425db97ffe6","value":1600}},"605624e73cb04b89ba2c49ca7141fbee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"621185c26d9f4e31a2c6d3e7d2537c0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b94e6121cee34f2fbb03bf87fb42122d","placeholder":"​","style":"IPY_MODEL_2d6386f87e0f47e0886096d8e03622ce","value":"Map: 100%"}},"6251035105b94061923104664e7d156d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e1730a6f9b9416e950bea7e9dad524e","IPY_MODEL_e3d0ed152854480086dd0889fd7e7645","IPY_MODEL_f42edb1c03554e09b58805c0f9c936e5"],"layout":"IPY_MODEL_109acbf38f4b44fe981814a1e8416b99"}},"6536ee1eb50c4a0e9bbdf6f94dd4f54a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_33069cb31b0148aab7df2582687fb05a","max":400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7bbec97aa2a455daca47a0804b886f3","value":400}},"67d565ba01584962a2751db812253461":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68c1693c00444046b39687cba582110f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05588b13251f4eee85d640ab9a5f9b84","placeholder":"​","style":"IPY_MODEL_67d565ba01584962a2751db812253461","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"69374bb0212d4ce4bdf8aaa9aacaab9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c88d66d54cd14e61a9ed73267e6b551d","placeholder":"​","style":"IPY_MODEL_496ce7354dd343fc9478c0441245555b","value":"Map: 100%"}},"6a7a16bf6af94f8ea32fe75d03134bad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ed9027106a44f2fad0de4af2471b8a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8576516d260472db12601aa4d750e87","max":1520013706,"min":0,"orientation":"horizontal","style":"IPY_MODEL_327c4580e3b14ca4bd86212a8b888d1e","value":1520013706}},"6f374e52eb374a6eb07e0834001ce49b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"702fcbba8d034515aeda64cc069483d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e9348ee3f1a4504a052cbc48162fe0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f54cc316afc34d888a0d2323049b6433","placeholder":"​","style":"IPY_MODEL_d5153e2d3d5d4050ad6f16a78c4c0968","value":" 1600/1600 [00:04&lt;00:00, 335.95 examples/s]"}},"80b64cd55fb0470b9b119425db97ffe6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88e0272ea0b84f4f9f9357892d2b6035":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"8a202ed6bc4145cd992a8ac065c40233":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69374bb0212d4ce4bdf8aaa9aacaab9a","IPY_MODEL_5ed5cb64c8284ee08afc1d3950399f66","IPY_MODEL_7e9348ee3f1a4504a052cbc48162fe0d"],"layout":"IPY_MODEL_db683467284945a880e18fb9981ee595"}},"93afe16d25384dec99e5f5e814d6171a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"946b00ca665d46198ee9d1f0002ca16f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95b4fc7f0eb54bbebffe7d0fc6b07737":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7bbec97aa2a455daca47a0804b886f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b94e6121cee34f2fbb03bf87fb42122d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba06d27a49ee48d79c6ca5af03fb2cfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c608efb9261647c698df280d187c515f","placeholder":"​","style":"IPY_MODEL_95b4fc7f0eb54bbebffe7d0fc6b07737","value":"Downloading (…)neration_config.json: 100%"}},"c0fa055d96484361aaae4081cde0db18":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3969ceca8a0402fafc008dc66be5b00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf956ae573224999b3c70fe2ac1c2508","placeholder":"​","style":"IPY_MODEL_605624e73cb04b89ba2c49ca7141fbee","value":" 400/400 [00:00&lt;00:00, 430.89 examples/s]"}},"c608efb9261647c698df280d187c515f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8576516d260472db12601aa4d750e87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c88d66d54cd14e61a9ed73267e6b551d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8bd8bf4675f48529f392eacc2deb9d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fdb05cd7074460582c63a18a6b722d1","max":1600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f03aa2c303542f397c984ab12573b00","value":1600}},"cdeb3e398a154e37b6d1224389ddc10a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf956ae573224999b3c70fe2ac1c2508":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5153e2d3d5d4050ad6f16a78c4c0968":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d53756d5c9854fcfba5da6a0c2fdd64a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6d564815acc43b5bda033f56e5929ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7e150c92c86472d95ced8803ee441b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_946b00ca665d46198ee9d1f0002ca16f","placeholder":"​","style":"IPY_MODEL_f5856791584d488a9ef3f22751d86315","value":" 1600/1600 [00:01&lt;00:00, 1345.57 examples/s]"}},"db683467284945a880e18fb9981ee595":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"e3d0ed152854480086dd0889fd7e7645":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_93afe16d25384dec99e5f5e814d6171a","max":400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec4c8ddf082146c69a7ab511a0d1997d","value":400}},"ec31ba4be7c74b0c8f74306587297b17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8a58a0249cd4fa38720d85cf8299aa4","placeholder":"​","style":"IPY_MODEL_d53756d5c9854fcfba5da6a0c2fdd64a","value":" 1.52G/1.52G [00:06&lt;00:00, 247MB/s]"}},"ec4c8ddf082146c69a7ab511a0d1997d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ecc820dc29194315919149c4abf1740d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_547f70ad26e24430aa9f0caeba38b589","placeholder":"​","style":"IPY_MODEL_03542ccd3a5f47c486d1f97f8d93cfb0","value":" 124/124 [00:00&lt;00:00, 4.69kB/s]"}},"ed1b8b67ae124261ace68fbacb4ae8f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0a6cc9b5eef4d338bdeb4026b8fea64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f42edb1c03554e09b58805c0f9c936e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_212d461178844de19e28de92dd5baf9e","placeholder":"​","style":"IPY_MODEL_ed1b8b67ae124261ace68fbacb4ae8f3","value":" 400/400 [00:00&lt;00:00, 1258.91 examples/s]"}},"f54cc316afc34d888a0d2323049b6433":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5856791584d488a9ef3f22751d86315":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8025bca99814998a7314464756b5094":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8febc8b090d4c3db9297057d03125b9","placeholder":"​","style":"IPY_MODEL_f0a6cc9b5eef4d338bdeb4026b8fea64","value":"Map: 100%"}},"f8a58a0249cd4fa38720d85cf8299aa4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8febc8b090d4c3db9297057d03125b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc74dad4d52e43598bcded725a0ff7f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba06d27a49ee48d79c6ca5af03fb2cfa","IPY_MODEL_4d01d399f9ce46bfbf381055420ca96a","IPY_MODEL_ecc820dc29194315919149c4abf1740d"],"layout":"IPY_MODEL_702fcbba8d034515aeda64cc069483d6"}}}}},"nbformat":4,"nbformat_minor":0}
