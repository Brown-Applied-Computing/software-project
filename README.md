# Brown Applied Computing Software Project
This is the Spring 2023 Brown Applied Computing software project. We are demonstrating innovative approaches to LLMs, debugging, and AI explainability. To do this, we are incorporating GPT and AI technology into gaming. <img style="float: right; display: inline-block; margin: 5%;" src="bac.jpg" width="30%">

# Plan
Our plan is not set in stone. Edit the [Google doc plan](https://docs.google.com/document/d/1_AmFrudoSJa6s30vHYEYI6L1M-KW2zWXDtEwJlGhOCQ/edit?usp=sharing) as we try different things and come up with new ideas. For now, our general plan is as follows.
1. Create a fun text-based game.
2. Incorporate GPT-2 into the game, either as a player, as an NPC, or for prompt generation.
3. Expand to using AI in other games.
4. Create an AI that can exploit bugs in a game to perform better without playing fairly.
5. Create a system that generalizes the bug-exploting game model to multiple games.
* Bonus: use a more advanced GPT model rather than GPT-2.

We will not necessarily finish all the goals, but with each step we will have something interesting to show.

# Significance
AI developers often use games to explore broadly relevant topics. Our project has a number of implications beyond gaming. First of all, incorporating GPT technology into gaming is a great example of application-specific language models. As language models become more powerful and widespread, fine-tuned versions will also become more prevalent. Organizations will apply these in a nearly limitless set of domains, from E-commerce to scientific writing.

We are also interested in finding more effective debugging strategies. Tools like GitHub Copilot exist to help write code, but finding bugs can still be difficult. In games, AI models can reveal bugs that human testing would not have found. We want to eventually generalize this system to multiple games as a first step to AI-based testing and debugging in a wider range of contexts. This would allow developers to concentrate on more conceptually difficult ideas and create better products.

Finally, we hope to work on AI explainability and interpretability in gaming. AI models in games have often been shown to exploit aspects of game design to gain artificially high scores without playing the game properly. This is amusing to watch in games, but also concerning because it shows that AI may dangerously prioritize one goal in its training at the expense of everything else. As we develop our project, we will pay particular attention to trying to explain why AI behaves the way it does and whether or not that is aligned with the goals we want to achieve.

# Technical Details
The technical details for this project are always changing, and for now will be most up to date in our [Google doc plan](https://docs.google.com/document/d/1_AmFrudoSJa6s30vHYEYI6L1M-KW2zWXDtEwJlGhOCQ/edit?usp=sharing).